{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "class VGGNet:\n",
    "    def __init__(self, layers, **kwargs):\n",
    "        self.model = Sequential()\n",
    "        self.input_dims = kwargs['input_dims']\n",
    "        self.channel_dimension = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "        self.n_classes = kwargs['n_classes']\n",
    "        \n",
    "        \n",
    "        self.model.add(Conv2D(64, (3,3), padding=\"same\", \n",
    "                                  input_shape=self.input_dims))\n",
    "        self.model.add(Activation(\"relu\"))            \n",
    "        self.model.add(BatchNormalization(axis=self.channel_dimension))\n",
    "        \n",
    "        self.model.add(Conv2D(64, (3,3), padding=\"same\", \n",
    "                                  input_shape=self.model.layers[-1].output_shape))\n",
    "        self.model.add(Activation(\"relu\"))\n",
    "        self.model.add(BatchNormalization(axis=self.channel_dimension))\n",
    "    \n",
    "        self.model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "        \n",
    "        for _ in range(2):\n",
    "            self.model.add(Conv2D(128, (3,3), padding=\"same\", \n",
    "                                  input_shape=self.model.layers[-1].output_shape))\n",
    "            self.model.add(Activation(\"relu\"))\n",
    "            self.model.add(BatchNormalization(axis=self.channel_dimension))\n",
    "            \n",
    "        self.model.add(MaxPooling2D(pool_size=(3,3), data_format = 'channels_last'))\n",
    "        \n",
    "        for _ in range(3):\n",
    "            self.model.add(Conv2D(256, (3,3), padding=\"same\", \n",
    "                                  input_shape=self.model.layers[-1].output_shape))\n",
    "            self.model.add(Activation(\"relu\"))\n",
    "            self.model.add(BatchNormalization(axis=self.channel_dimension))\n",
    "            \n",
    "        self.model.add(MaxPooling2D(pool_size=(3,3), data_format = 'channels_last'))\n",
    "        \n",
    "        for _ in range(3):\n",
    "            self.model.add(Conv2D(512, (3,3), padding=\"same\", \n",
    "                                  input_shape=self.model.layers[-1].output_shape))\n",
    "            self.model.add(Activation(\"relu\"))\n",
    "            self.model.add(BatchNormalization(axis=self.channel_dimension))\n",
    "            \n",
    "#         self.model.add(MaxPooling2D(pool_size=(3,3), data_format = 'channels_last'))\n",
    "        \n",
    "        for _ in range(3):\n",
    "            self.model.add(Conv2D(512, (3,3), padding=\"same\", \n",
    "                                  input_shape=self.model.layers[-1].output_shape))\n",
    "            self.model.add(Activation(\"relu\"))\n",
    "            self.model.add(BatchNormalization(axis=self.channel_dimension))\n",
    "            \n",
    "#         self.model.add(MaxPooling2D(pool_size=(3,3), data_format = 'channels_last'))\n",
    "        \n",
    "        self.model.add(Dense(4096, input_shape = self.model.layers[-1].output_shape))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(4096, input_shape = self.model.layers[-1].output_shape))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(self.n_classes, input_shape = self.model.layers[-1].output_shape))\n",
    "        self.model.add(Activation(\"softmax\"))\n",
    "    def compile(self, l, opt, met):\n",
    "        self.model.compile(optimizer=opt,\n",
    "                          loss= l,\n",
    "                          metrics=met)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_116 (Conv2D)          (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 1, 1, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1, 1, 4096)        2101248   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1, 1, 10)          40970     \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 1, 1, 10)          0         \n",
      "=================================================================\n",
      "Total params: 33,653,962\n",
      "Trainable params: 33,645,514\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "    testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "else:\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "             \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
    "\n",
    "opt = SGD(lr = INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "vgg = VGGNet(4, input_dims=(28,28,1), n_classes=10)\n",
    "vgg.compile(\"mse\", opt, [\"accuracy\"])\n",
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
