{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Understanding\n",
    "\n",
    "We had little missing data(based on the count of each feature). We found that only the \"Code\" feature had missing values. We decided not to interpolate these values, as the code is nominal data, and the result of the ensuing play after each pitch is not something we thought was wise to interpolate. We have more than enough data without these rows anyway.\n",
    "    \n",
    "Even with a mostly pristine dataset, we still had some housekeeping items to take care of.\n",
    "    \n",
    "* The first bit of data cleanup we did is to get rid of duplicate rows.<br> Even without the unique identifier, there is a sufficient number of features, many of which relate to the state of the ball game, to determine if an entry is a duplicate.<br> The probability of each and every feature being identical for 2 seperate pitches,especially considering some of the data is unrelated to the actual throw,<br> is incredibly low.\n",
    "        \n",
    "* The next important step we took to groom out dataset is to remove pitches where the prediction class is listed as unknown, or where it was listed as 'FA'.<br> While the data itself was in great condition as is, the overview written by the data aggregator wasn't quite as outstanding. <br>This value('FA') wasn't found in the key that was provided to translate the pitch_type codes into their real-world values, so we dropped this data.<br> Likewise, we dropped all unknown prediction classes, as it's an incorrect practice to interpolate this data.\n",
    "        \n",
    "       \n",
    "* Next, we removed outliers in the data. It isn't always easy to differentiate true outliers from valuable data points that happen to be unusual.<br> Luckily, some of the features had very obvious outliers well over 10 times the standard deviation apart from the mean. <br> After some tweaking of the parameters,<br> we found that removing any value more than 12 standard deviations away from the mean produced acceptable numbers that make<br> sense in the context of the business case.We enlisted the advice of a subject matter expert to help us decide on what summary statistics look most realistic.\n",
    "      \n",
    "\n",
    "* Finally, we removed any data points that the classifiers were not fully confident in. <br>Fortunately, the curators of this data provided a confidence interval that we could use to remove pitches that were 'guesses' of sorts. <br>This is helpful because we can train a prediction model based only on data that is concrete.<br> We also removed any values that were missing in this step, as we have sufficient data to do so, and interpolating this data can be difficult.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 39 attributes and 15 prediction classes describing the information of the pitch thrown. Of these 39 attributes, we have chosen 23 attributes that are most likely candidates to use for the classification task. The important numeric features among these are: <br><br>1. Break length <br>2. Break angle <br>3. Start speed <br>4. End speed <br>5. Spin rate <br>6. Pitch Number <br>7. ax <br> 8. ay <br> 9. az <br> 10. Nasty <br> 11. x <br> 12. y<br><br>\n",
    "The important categorical features among these are:<br><br> 1. on_1b <br> 2. on_2b <br> 3. on_3b <br> 4. outs <br> 5. s_count and <br> 6. b_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../pitches.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#drop unkown prediction classes and prediction classes with no definition from data source\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df.pitch_type != 'UN']\n",
    "df = df[df.pitch_type != 'FA']\n",
    "df = df[df.pitch_type != 'SC']\n",
    "df = df[df.pitch_type != 'FO']\n",
    "df = df[df.pitch_type != 'EP']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features = ['break_angle', 'break_length', 'end_speed', 'start_speed', 'spin_rate', 'pitch_num',\n",
    "           'ax', 'ay', 'az', 'nasty', 'sz_bot', 'sz_top', 'vx0', 'vy0', 'vz0', 'x', 'y']\n",
    "categorical_features = ['on_1b', 'on_2b', 'on_3b', 'outs', 's_count', 'b_count']\n",
    "\n",
    "#remove wild pitches or intentional walks as break length outliers. Code sourced from https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "for feature in features:\n",
    "    if feature != 'pitch_type':\n",
    "        df = df[np.abs(df[feature]-df[feature].mean()) <= (12*df[feature].std())]\n",
    "\n",
    "#drop data points where prediction class is unreliable\n",
    "df = df[df.type_confidence >= 1.0]\n",
    "\n",
    "#Drop any data with incomplete records\n",
    "df.dropna(inplace=True)\n",
    "#normalize angles from -1 to 1 to avoid neuron saturation\n",
    "df['break_angle']/=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ab_id', 'ax', 'ay', 'az', 'b_count', 'b_score', 'break_angle',\n",
      "       'break_length', 'break_y', 'code', 'end_speed', 'nasty', 'on_1b',\n",
      "       'on_2b', 'on_3b', 'outs', 'pfx_x', 'pfx_z', 'pitch_num', 'pitch_type',\n",
      "       'px', 'pz', 's_count', 'spin_dir', 'spin_rate', 'start_speed', 'sz_bot',\n",
      "       'sz_top', 'type', 'type_confidence', 'vx0', 'vy0', 'vz0', 'x', 'x0',\n",
      "       'y', 'y0', 'z0', 'zone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasimon/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasimon/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/rasimon/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/rasimon/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/rasimon/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type_CH\": 9.608821944061807,\n",
      "  \"type_CU\": 12.034203741034176,\n",
      "  \"type_FC\": 18.887060935591624,\n",
      "  \"type_FF\": 2.8182085658953877,\n",
      "  \"type_FS\": 63.79264413518887,\n",
      "  \"type_FT\": 8.602139295480136,\n",
      "  \"type_KC\": 40.4853799324985,\n",
      "  \"type_KN\": 385.2064825930372,\n",
      "  \"type_SI\": 11.877514760045159,\n",
      "  \"type_SL\": 6.186743532519365\n",
      "}\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import gc\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder()\n",
    "X = df\n",
    "y = pd.get_dummies(df['pitch_type'],prefix='type')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state=None)\n",
    "\n",
    "X_train_ohe = ohe.fit_transform(X_train[categorical_features])\n",
    "print(type(X_train_ohe))\n",
    "X_test_ohe = ohe.transform(X_test[categorical_features].values)\n",
    "\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]\n",
    "\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.fit_transform(X_test)\n",
    "testing_weights = {}\n",
    "weights = []\n",
    "for col in y_test.columns:\n",
    "    testing_weights[col] = 1/(len(y_train[y_train[col] == 1]) / len(y_train))\n",
    "print(json.dumps(testing_weights, indent=2))\n",
    "for _, row in y_test.iterrows():\n",
    "    for col in testing_weights.keys():\n",
    "        if row[col] == 1:\n",
    "            weights.append(testing_weights[col])\n",
    "print(\"done\")\n",
    "for i in weights:\n",
    "    if i > 100:\n",
    "        i = 100\n",
    "del testing_weights\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists 15 prediction classes describing the information of the pitch thrown. The prediction classes are as follows: <br><br>1. FC – Cutter <br> 2. FF – Four Seam Fastball <br> 3. FS – Splitter <br> 4. FT – Two Seam Fastball <br> 5. SI – Sinker <br> 6. CU – Curveball <br> 7. KC – Knuckle Curve <br> 8. KN – Knuckleball <br> 9. SL – Slider <br> 10. SC - Screwball <br> 11. CH – Changeup <br> 12. EP – Eephus <br> 13. FO – Pitchout <br> 14. PO – Pitchout <br> 15. IN – Intentional Ball\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Wide and Deep Network\n",
    "\n",
    "We have used a wide network of 1 fully connected layer with relu activation and a dense nework of 4-layers with ReLu activation and an output layer with signoid activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0414 21:18:02.716393 140053863049024 deprecation.py:237] From /home/rasimon/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4139: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0414 21:18:02.741734 140053863049024 deprecation.py:506] From /home/rasimon/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 34)           612         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 27)           945         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 27)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 19)           532         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 19)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 15)           300         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 15)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            54          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 13)           208         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_1 (Concatenate)          (None, 16)           0           dense_1[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           concat_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 10)           170         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,821\n",
      "Trainable params: 2,821\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Input, Dropout\n",
    "from keras.layers import Embedding, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "inputs = Input(shape=(X_train[features].shape[1],))\n",
    "inputs_wide = Input(shape=(X_train_ohe.shape[1],))\n",
    "output_wide = Dense(units=3, activation='relu')(inputs_wide)\n",
    "\n",
    "x = Dense(units=34, activation='relu')(inputs)\n",
    "x = Dense(units=27, activation='relu')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(units=19, activation='relu')(x)\n",
    "x = Dropout(.25)(x)\n",
    "x = Dense(units=15, activation='relu')(x)\n",
    "x = Dropout(.25)(x)\n",
    "output_deep = Dense(13, activation ='sigmoid')(x)\n",
    "\n",
    "final_branch = concatenate([output_wide, output_deep], name='concat_1')\n",
    "final_branch = Dropout(.3)(final_branch)\n",
    "final_branch = Dense(units=10, activation='softmax', name = 'combined')(final_branch)\n",
    "\n",
    "model = Model(inputs = [inputs, inputs_wide], outputs = final_branch)\n",
    "model.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 12)\t1.0\n",
      "  (1, 9)\t1.0\n",
      "  (1, 8)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 12)\t1.0\n",
      "  (2, 9)\t1.0\n",
      "  (2, 7)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 14)\t1.0\n",
      "  (3, 11)\t1.0\n",
      "  (3, 7)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 14)\t1.0\n",
      "  :\t:\n",
      "  (1283503, 1)\t1.0\n",
      "  (1283504, 13)\t1.0\n",
      "  (1283504, 11)\t1.0\n",
      "  (1283504, 8)\t1.0\n",
      "  (1283504, 4)\t1.0\n",
      "  (1283504, 2)\t1.0\n",
      "  (1283504, 1)\t1.0\n",
      "  (1283505, 14)\t1.0\n",
      "  (1283505, 9)\t1.0\n",
      "  (1283505, 8)\t1.0\n",
      "  (1283505, 4)\t1.0\n",
      "  (1283505, 2)\t1.0\n",
      "  (1283505, 0)\t1.0\n",
      "  (1283506, 13)\t1.0\n",
      "  (1283506, 10)\t1.0\n",
      "  (1283506, 7)\t1.0\n",
      "  (1283506, 4)\t1.0\n",
      "  (1283506, 2)\t1.0\n",
      "  (1283506, 0)\t1.0\n",
      "  (1283507, 13)\t1.0\n",
      "  (1283507, 9)\t1.0\n",
      "  (1283507, 6)\t1.0\n",
      "  (1283507, 4)\t1.0\n",
      "  (1283507, 2)\t1.0\n",
      "  (1283507, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  91968/1283508 [=>............................] - ETA: 4:04 - loss: 0.0752 - acc: 0.4305"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-848d7bef2090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_ohe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, X_train_ohe] ,y_train, epochs=2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['acc']\n",
    "\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35649982439245564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat_proba = model.predict([X_test, X_test_ohe])\n",
    "yhat = np.round(yhat_proba)\n",
    "print(mt.accuracy_score(y_test, yhat,sample_weight=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 50)           900         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 34)           1734        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 26)           910         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 24)           648         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 20)           500         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            54          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           336         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_1 (Concatenate)          (None, 19)           0           dense_1[0][0]                    \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16)           320         concat_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 10)           170         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,572\n",
      "Trainable params: 5,572\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs_2 = Input(shape=(X_train[features].shape[1],))\n",
    "inputs_wide_2 = Input(shape=(X_train_ohe.shape[1],))\n",
    "output_wide_2 = Dense(units=6, activation='relu')(inputs_wide)\n",
    "output_wide_2 = Dense(3, activation='relu')(inputs_wide)\n",
    "\n",
    "x = Dense(units=50, activation='relu')(inputs)\n",
    "x = Dense(units=34, activation='relu')(x)\n",
    "x = Dense(units=30, activation='relu')(x)\n",
    "x = Dense(units=26, activation='relu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(units=22, activation='relu')(x)\n",
    "x = Dropout(.15)(x)\n",
    "x = Dense(units=18, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "output_deep = Dense(16, activation ='sigmoid')(x)\n",
    "x = Dropout(.25)(x)\n",
    "\n",
    "final_branch = concatenate([output_wide, output_deep], name='concat_1')\n",
    "final_branch = Dense(16,activation='relu')(final_branch)\n",
    "x = Dropout(.3)(x)\n",
    "final_branch = Dense(units=10, activation='softmax', name = 'combined')(final_branch)\n",
    "\n",
    "model = Model(inputs = [inputs, inputs_wide], outputs = final_branch)\n",
    "model.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1283508/1283508 [==============================] - 179s 139us/step - loss: 0.0482 - acc: 0.6455\n",
      "Epoch 2/10\n",
      "1283508/1283508 [==============================] - 116s 90us/step - loss: 0.0401 - acc: 0.7078\n",
      "Epoch 3/10\n",
      "1283508/1283508 [==============================] - 102s 79us/step - loss: 0.0375 - acc: 0.7253\n",
      "Epoch 4/10\n",
      "1283508/1283508 [==============================] - 100s 78us/step - loss: 0.0367 - acc: 0.7320\n",
      "Epoch 5/10\n",
      "1283508/1283508 [==============================] - 101s 78us/step - loss: 0.0362 - acc: 0.7356\n",
      "Epoch 6/10\n",
      "1283508/1283508 [==============================] - 101s 79us/step - loss: 0.0360 - acc: 0.7380\n",
      "Epoch 7/10\n",
      "1283508/1283508 [==============================] - 101s 79us/step - loss: 0.0358 - acc: 0.7398\n",
      "Epoch 8/10\n",
      "1283508/1283508 [==============================] - 101s 79us/step - loss: 0.0357 - acc: 0.7413\n",
      "Epoch 9/10\n",
      "1283508/1283508 [==============================] - 101s 78us/step - loss: 0.0357 - acc: 0.7406\n",
      "Epoch 10/10\n",
      "1283508/1283508 [==============================] - 101s 79us/step - loss: 0.0357 - acc: 0.7404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f396c0b9a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit([X_train, X_train_ohe] ,y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cc5d7d1655f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48314971394609924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yhat_proba = model.predict([X_test, X_test_ohe])\n",
    "yhat = np.round(yhat_proba)\n",
    "print(mt.accuracy_score(y_test, yhat,sample_weight=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
