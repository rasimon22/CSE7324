{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../pitches.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#drop unkown prediction classes and prediction classes with no definition from data source\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df.pitch_type != 'UN']\n",
    "df = df[df.pitch_type != 'FA']\n",
    "\n",
    "features = ['break_angle', 'break_length', 'end_speed', 'start_speed', 'spin_rate', 'pitch_num',\n",
    "           'ax', 'ay', 'az', 'nasty', 'sz_bot', 'sz_top', 'vx0', 'vy0', 'vz0', 'x', 'y']\n",
    "categorical_features = ['on_1b', 'on_2b', 'on_3b', 'outs', 's_count', 'b_count']\n",
    "\n",
    "print df\n",
    "#remove wild pitches or intentional walks as break length outliers. Code sourced from https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "for feature in features:\n",
    "    if feature != 'pitch_type':\n",
    "        df = df[np.abs(df[feature]-df[feature].mean()) <= (12*df[feature].std())]\n",
    "\n",
    "#drop data points where prediction class is unreliable\n",
    "df = df[df.type_confidence >= 1.0]\n",
    "\n",
    "#Drop any data with incomplete records\n",
    "df.dropna(inplace=True)\n",
    "#normalize angles from -1 to 1 to avoid neuron saturation\n",
    "df['break_angle']/=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ab_id', 'ax', 'ay', 'az', 'b_count', 'b_score', 'break_angle',\n",
      "       'break_length', 'break_y', 'code', 'end_speed', 'nasty', 'on_1b',\n",
      "       'on_2b', 'on_3b', 'outs', 'pfx_x', 'pfx_z', 'pitch_num', 'pitch_type',\n",
      "       'px', 'pz', 's_count', 'spin_dir', 'spin_rate', 'start_speed', 'sz_bot',\n",
      "       'sz_top', 'type', 'type_confidence', 'vx0', 'vy0', 'vz0', 'x', 'x0',\n",
      "       'y', 'y0', 'z0', 'zone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type_CH': 0.10388866269270682, 'type_CU': 0.08311840371062078, 'type_EP': 0.00036277888626881915, 'type_FC': 0.052831816175423055, 'type_FF': 0.3543812556976137, 'type_FO': 0.0003472089769868956, 'type_FS': 0.015635302900907647, 'type_FT': 0.11644735151950637, 'type_KC': 0.024774061153932686, 'type_KN': 0.002632093164109179, 'type_SC': 5.683016887902103e-05, 'type_SI': 0.08388132926543504, 'type_SL': 0.16164290568761}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "X = df[features].values\n",
    "y = pd.get_dummies(df['pitch_type'],prefix='type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state=None)\n",
    "testing_weights = {}\n",
    "weights = []\n",
    "for col in y_test.columns:\n",
    "    testing_weights[col] = (len(y_train[y_train[col] == 1]) / len(y_train))\n",
    "print(testing_weights)\n",
    "for _, row in y_test.iterrows():\n",
    "    for col in testing_weights.keys():\n",
    "        if row[col] == 1:\n",
    "            weights.append(testing_weights[col])\n",
    "del testing_weights\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 34)                612       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 27)                945       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 19)                532       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 15)                300       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 13)                208       \n",
      "=================================================================\n",
      "Total params: 2,597\n",
      "Trainable params: 2,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(units=34, activation='relu')(inputs)\n",
    "x = Dense(units=27, activation='relu')(x)\n",
    "x = Dense(units=19, activation='relu')(x)\n",
    "x = Dense(units=15, activation='relu')(x)\n",
    "predictions = Dense(13, activation ='softmax')(x)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "model.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1284529/1284529 [==============================] - 72s 56us/step - loss: 0.0338 - acc: 0.6772\n",
      "Epoch 2/10\n",
      "1284529/1284529 [==============================] - 61s 48us/step - loss: 0.0293 - acc: 0.7205\n",
      "Epoch 3/10\n",
      "1284529/1284529 [==============================] - 52s 40us/step - loss: 0.0284 - acc: 0.7296\n",
      "Epoch 4/10\n",
      "1284529/1284529 [==============================] - 48s 37us/step - loss: 0.0280 - acc: 0.7337\n",
      "Epoch 5/10\n",
      "1284529/1284529 [==============================] - 46s 36us/step - loss: 0.0277 - acc: 0.7371\n",
      "Epoch 6/10\n",
      "1284529/1284529 [==============================] - 46s 35us/step - loss: 0.0275 - acc: 0.7396\n",
      "Epoch 7/10\n",
      "1284529/1284529 [==============================] - 44s 34us/step - loss: 0.0273 - acc: 0.7412\n",
      "Epoch 8/10\n",
      "1284529/1284529 [==============================] - 43s 34us/step - loss: 0.0272 - acc: 0.7428\n",
      "Epoch 9/10\n",
      "1284529/1284529 [==============================] - 43s 34us/step - loss: 0.0271 - acc: 0.7446\n",
      "Epoch 10/10\n",
      "1284529/1284529 [==============================] - 42s 33us/step - loss: 0.0269 - acc: 0.7461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64dc496ac8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7649704594772639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat_proba = model.predict(X_test)\n",
    "yhat = np.round(yhat_proba)\n",
    "print(mt.accuracy_score(y_test, yhat,sample_weight=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
