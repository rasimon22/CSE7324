{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 0.16140710382513662\n",
      "neutral 0.21168032786885246\n",
      "negative 0.6269125683060109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#prepare data and class variables\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import one_hot, text_to_word_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "tweets_df = pd.read_csv('../tweets.csv')\n",
    "\n",
    "print('positive', len(tweets_df[tweets_df['airline_sentiment'] == 'positive'])/len(tweets_df))\n",
    "print('neutral', len(tweets_df[tweets_df['airline_sentiment'] == 'neutral'])/len(tweets_df))\n",
    "print('negative', len(tweets_df[tweets_df['airline_sentiment'] == 'negative'])/len(tweets_df))\n",
    "\n",
    "tweets_df[tweets_df['airline_sentiment'] == 'positive']['airline_sentiment'] = 0\n",
    "tweets_df[tweets_df['airline_sentiment'] == 'neutral']['airline_sentiment'] = 1\n",
    "tweets_df[tweets_df['airline_sentiment'] == 'positive']['airline_sentiment'] = 2\n",
    "\n",
    "X = tweets_df['text'].tolist()\n",
    "y = tweets_df['airline_sentiment'].tolist()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "y = dummy_y\n",
    "\n",
    "vocab_size = 0\n",
    "for entry in X:\n",
    "    words = set(text_to_word_sequence(entry))\n",
    "    vocab_size += len(words)\n",
    "    \n",
    "X = [one_hot(entry, round(vocab_size*1.3)) for entry in X]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, random_state=42)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 50)           12416200  \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 25)                1900      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 12,418,178\n",
      "Trainable params: 12,418,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#modeling\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "EMBED_SIZE = 50\n",
    "rnns = []\n",
    "input_holder = Input(shape=(X_train.shape[1], ))\n",
    "input_embed = Embedding(vocab_size,\n",
    "                       50,\n",
    "                       input_length=500)(input_holder)\n",
    "x = SimpleRNN(25, dropout=0.2, recurrent_dropout=0.2)(input_embed)\n",
    "x = Dense(3, activation='sigmoid')(x)\n",
    "rnn=Model(inputs=input_holder,outputs=x)\n",
    "rnn.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "rnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 500, 50)           12416200  \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 12,421,403\n",
      "Trainable params: 12,421,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 500, 50)           12416200  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 12,436,553\n",
      "Trainable params: 12,436,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 500, 50)           12416200  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 50)                15150     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 12,431,503\n",
      "Trainable params: 12,431,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_holder = Input(shape=(X_train.shape[1], ))\n",
    "input_embed = Embedding(vocab_size,\n",
    "                       50,\n",
    "                       input_length=500)(input_holder)\n",
    "for func in [SimpleRNN, LSTM, GRU]:\n",
    "    \n",
    "    x = func(50, dropout=0.2, recurrent_dropout=0.2)(input_embed)\n",
    "    x = Dense(3, activation='sigmoid')(x)\n",
    "    rnn=Model(inputs=input_holder, outputs=x)\n",
    "    rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(rnn.summary())\n",
    "    rnns.append(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= simple ========\n",
      "Train on 10980 samples, validate on 3660 samples\n",
      "Epoch 1/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.3313 - acc: 0.8799 - val_loss: 1.0694 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.2738 - acc: 0.9042 - val_loss: 1.0493 - val_acc: 0.6899\n",
      "Epoch 3/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.2381 - acc: 0.9138 - val_loss: 1.0704 - val_acc: 0.6880\n",
      "Epoch 4/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.2332 - acc: 0.9174 - val_loss: 1.0909 - val_acc: 0.6975\n",
      "Epoch 5/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.2064 - acc: 0.9243 - val_loss: 1.0765 - val_acc: 0.7033\n",
      "Epoch 6/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1962 - acc: 0.9302 - val_loss: 1.0871 - val_acc: 0.7003\n",
      "Epoch 7/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1863 - acc: 0.9339 - val_loss: 1.1023 - val_acc: 0.6943\n",
      "Epoch 8/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1817 - acc: 0.9341 - val_loss: 1.1370 - val_acc: 0.6970\n",
      "Epoch 9/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1723 - acc: 0.9387 - val_loss: 1.1297 - val_acc: 0.7036\n",
      "Epoch 10/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1757 - acc: 0.9362 - val_loss: 1.1162 - val_acc: 0.7087\n",
      "Epoch 11/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1520 - acc: 0.9464 - val_loss: 1.1497 - val_acc: 0.7079\n",
      "Epoch 12/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1398 - acc: 0.9509 - val_loss: 1.1635 - val_acc: 0.6997\n",
      "Epoch 13/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1381 - acc: 0.9514 - val_loss: 1.2014 - val_acc: 0.7093\n",
      "Epoch 14/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1306 - acc: 0.9536 - val_loss: 1.2090 - val_acc: 0.7096\n",
      "Epoch 15/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1259 - acc: 0.9569 - val_loss: 1.2072 - val_acc: 0.7112\n",
      "Epoch 16/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1297 - acc: 0.9526 - val_loss: 1.1953 - val_acc: 0.7145\n",
      "Epoch 17/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1235 - acc: 0.9550 - val_loss: 1.2230 - val_acc: 0.7137\n",
      "Epoch 18/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1106 - acc: 0.9597 - val_loss: 1.2650 - val_acc: 0.7134\n",
      "Epoch 19/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1127 - acc: 0.9617 - val_loss: 1.3351 - val_acc: 0.7057\n",
      "Epoch 20/20\n",
      "10980/10980 [==============================] - 25s 2ms/step - loss: 0.1441 - acc: 0.9474 - val_loss: 1.2400 - val_acc: 0.7175\n",
      "======= lstm ========\n",
      "Train on 10980 samples, validate on 3660 samples\n",
      "Epoch 1/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0737 - acc: 0.9724 - val_loss: 1.2320 - val_acc: 0.7486\n",
      "Epoch 2/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0557 - acc: 0.9813 - val_loss: 1.2805 - val_acc: 0.7522\n",
      "Epoch 3/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0501 - acc: 0.9830 - val_loss: 1.2599 - val_acc: 0.7475\n",
      "Epoch 4/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0457 - acc: 0.9860 - val_loss: 1.3411 - val_acc: 0.7481\n",
      "Epoch 5/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0392 - acc: 0.9867 - val_loss: 1.3452 - val_acc: 0.7464\n",
      "Epoch 6/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0418 - acc: 0.9858 - val_loss: 1.3807 - val_acc: 0.7486\n",
      "Epoch 7/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0377 - acc: 0.9868 - val_loss: 1.3908 - val_acc: 0.7489\n",
      "Epoch 8/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0361 - acc: 0.9880 - val_loss: 1.4312 - val_acc: 0.7385\n",
      "Epoch 9/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0351 - acc: 0.9875 - val_loss: 1.5059 - val_acc: 0.7492\n",
      "Epoch 10/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0343 - acc: 0.9893 - val_loss: 1.4453 - val_acc: 0.7475\n",
      "Epoch 11/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0327 - acc: 0.9879 - val_loss: 1.4990 - val_acc: 0.7475\n",
      "Epoch 12/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0333 - acc: 0.9878 - val_loss: 1.4750 - val_acc: 0.7475\n",
      "Epoch 13/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0319 - acc: 0.9883 - val_loss: 1.5362 - val_acc: 0.7470\n",
      "Epoch 14/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0308 - acc: 0.9897 - val_loss: 1.5400 - val_acc: 0.7484\n",
      "Epoch 15/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0277 - acc: 0.9902 - val_loss: 1.6064 - val_acc: 0.7484\n",
      "Epoch 16/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0267 - acc: 0.9905 - val_loss: 1.5924 - val_acc: 0.7527\n",
      "Epoch 17/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0301 - acc: 0.9900 - val_loss: 1.6018 - val_acc: 0.7355\n",
      "Epoch 18/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0277 - acc: 0.9901 - val_loss: 1.6406 - val_acc: 0.7445\n",
      "Epoch 19/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 1.6555 - val_acc: 0.7525\n",
      "Epoch 20/20\n",
      "10980/10980 [==============================] - 80s 7ms/step - loss: 0.0275 - acc: 0.9908 - val_loss: 1.5772 - val_acc: 0.7467\n",
      "======= gru ========\n",
      "Train on 10980 samples, validate on 3660 samples\n",
      "Epoch 1/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0537 - acc: 0.9803 - val_loss: 1.3083 - val_acc: 0.7355\n",
      "Epoch 2/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0447 - acc: 0.9836 - val_loss: 1.3706 - val_acc: 0.7484\n",
      "Epoch 3/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0386 - acc: 0.9866 - val_loss: 1.4177 - val_acc: 0.7467\n",
      "Epoch 4/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0381 - acc: 0.9863 - val_loss: 1.4200 - val_acc: 0.7399\n",
      "Epoch 5/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0375 - acc: 0.9873 - val_loss: 1.4640 - val_acc: 0.7440\n",
      "Epoch 6/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0330 - acc: 0.9885 - val_loss: 1.4924 - val_acc: 0.7399\n",
      "Epoch 7/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0336 - acc: 0.9878 - val_loss: 1.4991 - val_acc: 0.7369\n",
      "Epoch 8/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0325 - acc: 0.9888 - val_loss: 1.5203 - val_acc: 0.7393\n",
      "Epoch 9/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0333 - acc: 0.9883 - val_loss: 1.5707 - val_acc: 0.7437\n",
      "Epoch 10/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0311 - acc: 0.9892 - val_loss: 1.5759 - val_acc: 0.7393\n",
      "Epoch 11/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0333 - acc: 0.9882 - val_loss: 1.5596 - val_acc: 0.7451\n",
      "Epoch 12/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0305 - acc: 0.9888 - val_loss: 1.5817 - val_acc: 0.7456\n",
      "Epoch 13/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0315 - acc: 0.9890 - val_loss: 1.5999 - val_acc: 0.7402\n",
      "Epoch 14/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0295 - acc: 0.9903 - val_loss: 1.6232 - val_acc: 0.7404\n",
      "Epoch 15/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0306 - acc: 0.9886 - val_loss: 1.6151 - val_acc: 0.7423\n",
      "Epoch 16/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0273 - acc: 0.9898 - val_loss: 1.6200 - val_acc: 0.7445\n",
      "Epoch 17/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0270 - acc: 0.9906 - val_loss: 1.6287 - val_acc: 0.7429\n",
      "Epoch 18/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0282 - acc: 0.9893 - val_loss: 1.6823 - val_acc: 0.7448\n",
      "Epoch 19/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0244 - acc: 0.9911 - val_loss: 1.7279 - val_acc: 0.7459\n",
      "Epoch 20/20\n",
      "10980/10980 [==============================] - 65s 6ms/step - loss: 0.0259 - acc: 0.9903 - val_loss: 1.7413 - val_acc: 0.7522\n"
     ]
    }
   ],
   "source": [
    "for rnn, name in zip(rnns,['simple','lstm','gru']):\n",
    "    print('=======',name,'========')\n",
    "    rnn.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
