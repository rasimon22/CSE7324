{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../pitches.csv')\n",
    "#drop unkown prediction classes and prediction classes with no definition from data source\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df.pitch_type != 'UN']\n",
    "df = df[df.pitch_type != 'FA']\n",
    "\n",
    "features = ['break_angle', 'break_length', 'end_speed', 'start_speed', 'spin_rate', 'pitch_type']\n",
    "#remove wild pitches or intentional walks as break length outliers. Code sourced from https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "for feature in features:\n",
    "    if feature != 'pitch_type':\n",
    "        df = df[np.abs(df[feature]-df[feature].mean()) <= (12*df[feature].std())]\n",
    "\n",
    "#drop data points where prediction class is unreliable\n",
    "df = df[df.type_confidence >= 1.0]\n",
    "\n",
    "#Drop any data with incomplete records\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MultiLayerPerceptronBase(object):\n",
    "    def __init__(self, layers = 2, layer_width=[4, 3, 3], C = 0.0,\n",
    "                 epochs = 500, eta = 0.001, random_state = None):\n",
    "        np.random.seed(random_state)\n",
    "        self.C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.layer_width = layer_width\n",
    "        #add widths for input and output layers\n",
    "#         self.layer_width.insert(0, 8)\n",
    "        #output layer\n",
    "#         self.layer_width.append(8)\n",
    "        \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        self.weights = []\n",
    "        for idx, w in enumerate(self.layer_width[:-1]):\n",
    "            Wn_num_elements = (w + 1) * self.layer_width[idx+1]\n",
    "            self.weights.append(np.random.uniform(-1.0, 1.0, size = Wn_num_elements).\n",
    "                                reshape(self.layer_width[idx+1], w + 1))\n",
    "#         for w in self.weights:\n",
    "#             print(w.shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "        \n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _l2_reg(lambda_, weights):\n",
    "        t = 0\n",
    "        for w in weights:\n",
    "            t += np.mean(x[:, 1:] **2)\n",
    "        t = np.sqrt(t)\n",
    "        t *= (lambda_/len(weights))\n",
    "        return t\n",
    "    def _cost(self, A_n, y_enc, weights):\n",
    "        cost = np.mean((Y_enc - A_n) **2)\n",
    "        L2_term = self._l2_reg(self.C, weights)\n",
    "        return cost + L2_term\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(MultiLayerPerceptronBase):\n",
    "    def _feedforward(self, X):\n",
    "        A = []\n",
    "        Z = []\n",
    "        for idx, W_n in enumerate(self.weights):\n",
    "            if len(Z) > 0:\n",
    "                A_n = self._sigmoid(Z[-1])\n",
    "                A_n = self._add_bias_unit(A_n.reshape(-1, 1), how=\"row\")\n",
    "                Z_n = W_n @ A_n\n",
    "                A.append(A_n)\n",
    "                Z.append(Z_n)\n",
    "            else:\n",
    "                A_n = self._add_bias_unit(X.T.reshape(-1, 1), how=\"row\")\n",
    "                Z_n = W_n @ A_n\n",
    "                A.append(A_n)\n",
    "                Z.append(Z_n)\n",
    "        return A, Z\n",
    "    \n",
    "    def _get_gradient(self, A, Z, Y_enc):\n",
    "        gradients = []\n",
    "        for w in self.weights:\n",
    "            gradients.append(np.zeros(w.shape))\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.],\n",
      "       [1.],\n",
      "       [2.],\n",
      "       [3.],\n",
      "       [4.],\n",
      "       [5.],\n",
      "       [6.],\n",
      "       [7.],\n",
      "       [8.]]), array([[1.00000000e+00],\n",
      "       [6.97579406e-09],\n",
      "       [7.14217397e-01],\n",
      "       [3.32141668e-06],\n",
      "       [1.19518322e-03]]), array([[1.        ],\n",
      "       [0.7334974 ],\n",
      "       [0.63339697]]), array([[1.        ],\n",
      "       [0.53652242],\n",
      "       [0.6495008 ],\n",
      "       [0.28365213]])]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,5,6,7,8])\n",
    "x.reshape(1,8)\n",
    "mc = MultiLayerPerceptron(4, [x.shape[0], 4, 2,3,4])\n",
    "mc._initialize_weights()\n",
    "A, Z = mc._feedforward(x)\n",
    "print(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
