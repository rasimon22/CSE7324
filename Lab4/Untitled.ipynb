{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../pitches.csv')\n",
    "#drop unkown prediction classes and prediction classes with no definition from data source\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df.pitch_type != 'UN']\n",
    "df = df[df.pitch_type != 'FA']\n",
    "\n",
    "features = ['break_angle', 'break_length', 'end_speed', 'start_speed', 'spin_rate', 'pitch_type']\n",
    "#remove wild pitches or intentional walks as break length outliers. Code sourced from https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "for feature in features:\n",
    "    if feature != 'pitch_type':\n",
    "        df = df[np.abs(df[feature]-df[feature].mean()) <= (12*df[feature].std())]\n",
    "\n",
    "#drop data points where prediction class is unreliable\n",
    "df = df[df.type_confidence >= 1.0]\n",
    "\n",
    "#Drop any data with incomplete records\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MultiLayerPerceptronBase(object):\n",
    "    def __init__(self, layers = 2, layer_width=[4, 3, 3], C = 0.0,\n",
    "                 epochs = 500, eta = 0.001, random_state = None):\n",
    "        np.random.seed(random_state)\n",
    "        self.C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.layer_width = layer_width\n",
    "        #add widths for input and output layers\n",
    "#         self.layer_width.insert(0, 8)\n",
    "        #output layer\n",
    "#         self.layer_width.append(8)\n",
    "        \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        self.weights = []\n",
    "        for idx, w in enumerate(self.layer_width[:-1]):\n",
    "            Wn_num_elements = (w + 1) * self.layer_width[idx+1]\n",
    "            self.weights.append(np.random.uniform(-1.0, 1.0, size = Wn_num_elements).\n",
    "                                reshape(self.layer_width[idx+1], w + 1))\n",
    "#         for w in self.weights:\n",
    "#             print(w.shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "        \n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _l2_reg(lambda_, weights):\n",
    "        t = 0\n",
    "        for w in weights:\n",
    "            t += np.mean(x[:, 1:] **2)\n",
    "        t = np.sqrt(t)\n",
    "        t *= (lambda_/len(weights))\n",
    "        return t\n",
    "    def _cost(self, A_n, y_enc, weights):\n",
    "        cost = np.mean((Y_enc - A_n) **2)\n",
    "        L2_term = self._l2_reg(self.C, weights)\n",
    "        return cost + L2_term\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(MultiLayerPerceptronBase):\n",
    "    def _feedforward(self, X):\n",
    "        A = []\n",
    "        Z = []\n",
    "        for idx, W_n in enumerate(self.weights):\n",
    "            if len(Z) > 0:\n",
    "                A_n = self._sigmoid(Z[-1])\n",
    "                A_n = self._add_bias_unit(A_n.reshape(-1, 1), how=\"row\")\n",
    "                Z_n = W_n @ A_n\n",
    "                A.append(A_n)\n",
    "                Z.append(Z_n)\n",
    "            else:\n",
    "                A_n = self._add_bias_unit(X.T.reshape(-1, 1), how=\"row\")\n",
    "                Z_n = W_n @ A_n\n",
    "                A.append(A_n)\n",
    "                Z.append(Z_n)\n",
    "        A.append(self._sigmoid(Z[-1]))\n",
    "        return A, Z\n",
    "    \n",
    "    def _get_gradient(self, A, Z, Y_enc):\n",
    "        gradients = []\n",
    "        #gradient of objective function w/r to last activation\n",
    "        gradients.insert(0,np.zeros(self.weights[-1].shape))\n",
    "        for a, a2, y in zip(A[-1].T, A[-2].T,Y_enc.T):\n",
    "            dJ_dzl = -2*(y - a)*a*(1-a)\n",
    "            gradients[0]+= dJ_dzl[:, np.newaxis] @ a2[np.newaxis,:]\n",
    "            \n",
    "        return gradients\n",
    "                \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.],\n",
      "       [1.],\n",
      "       [2.],\n",
      "       [3.],\n",
      "       [4.],\n",
      "       [5.],\n",
      "       [6.],\n",
      "       [7.],\n",
      "       [8.]]), array([[1.00000000e+00],\n",
      "       [1.79690181e-06],\n",
      "       [5.93682552e-03],\n",
      "       [2.24345541e-07],\n",
      "       [9.99989317e-01],\n",
      "       [1.02513463e-01],\n",
      "       [8.13121590e-02],\n",
      "       [9.99955879e-01],\n",
      "       [8.75149686e-01],\n",
      "       [1.51239611e-07]]), array([[0.50023493],\n",
      "       [0.32891478],\n",
      "       [0.81055778],\n",
      "       [0.29737335],\n",
      "       [0.6977265 ],\n",
      "       [0.54202016],\n",
      "       [0.57902878],\n",
      "       [0.71641033],\n",
      "       [0.79036486]])]\n",
      "[array([[-7.49882369e-01, -1.34746499e-06, -4.45192079e-03,\n",
      "        -1.68232766e-07, -7.49874358e-01, -7.68730385e-02,\n",
      "        -6.09745544e-02, -7.49849284e-01, -6.56259320e-01,\n",
      "        -1.13411918e-07],\n",
      "       [-7.37716770e-01, -1.32560460e-06, -4.37969575e-03,\n",
      "        -1.65503468e-07, -7.37708888e-01, -7.56259007e-02,\n",
      "        -5.99853433e-02, -7.37684221e-01, -6.45612599e-01,\n",
      "        -1.11571997e-07],\n",
      "       [-3.65286897e-01, -6.56384688e-07, -2.16864457e-03,\n",
      "        -8.19504865e-08, -3.65282994e-01, -3.74468248e-02,\n",
      "        -2.97022662e-02, -3.65270780e-01, -3.19680713e-01,\n",
      "        -5.52458482e-08],\n",
      "       [-7.11501932e-01, -1.27849911e-06, -4.22406283e-03,\n",
      "        -1.59622286e-07, -7.11494331e-01, -7.29385269e-02,\n",
      "        -5.78537582e-02, -7.11470540e-01, -6.22670692e-01,\n",
      "        -1.07607276e-07],\n",
      "       [-5.49309988e-01, -9.87056114e-07, -3.26115756e-03,\n",
      "        -1.23235246e-07, -5.49304119e-01, -5.63116691e-02,\n",
      "        -4.46655811e-02, -5.49285752e-01, -4.80728463e-01,\n",
      "        -8.30774290e-08],\n",
      "       [-7.23841227e-01, -1.30067161e-06, -4.29731907e-03,\n",
      "        -1.62390552e-07, -7.23833494e-01, -7.42034708e-02,\n",
      "        -5.88570929e-02, -7.23809291e-01, -6.33469422e-01,\n",
      "        -1.09473466e-07],\n",
      "       [-6.92736125e-01, -1.24477880e-06, -4.11265351e-03,\n",
      "        -1.55412261e-07, -6.92728724e-01, -7.10147791e-02,\n",
      "        -5.63278699e-02, -6.92705561e-01, -6.06247802e-01,\n",
      "        -1.04769142e-07],\n",
      "       [-5.21565014e-01, -9.37201120e-07, -3.09644049e-03,\n",
      "        -1.17010785e-07, -5.21559442e-01, -5.34674357e-02,\n",
      "        -4.24095773e-02, -5.21542002e-01, -4.56447458e-01,\n",
      "        -7.88812899e-08],\n",
      "       [-4.00844662e-01, -7.20278500e-07, -2.37974482e-03,\n",
      "        -8.99277125e-08, -4.00840379e-01, -4.10919744e-02,\n",
      "        -3.25935448e-02, -4.00826976e-01, -3.50799080e-01,\n",
      "        -6.06235908e-08]])]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,5,6,7,8])\n",
    "x.reshape(1,8)\n",
    "mc = MultiLayerPerceptron(2, [x.shape[0], 9, 9])\n",
    "mc._initialize_weights()\n",
    "A, Z = mc._feedforward(x)\n",
    "y_enc = np.array([2,1,2])\n",
    "print(A)\n",
    "print(mc._get_gradient(A, Z, y_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
